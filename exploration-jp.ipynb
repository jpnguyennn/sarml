{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c07ba54c",
   "metadata": {},
   "source": [
    "# Import all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7432b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# baseline model libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# first model\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# second model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# third model\n",
    "from tensorflow.keras.layers import Bidirectional, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# fourth model\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "# ensemble model\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd8b19b",
   "metadata": {},
   "source": [
    "# Exploring the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e77d1111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (21464, 2)\n",
      "Valid Shape: (716, 2)\n",
      "Test Shape: (966, 2)\n",
      "----------\n",
      "                                                text  label\n",
      "0  states slow to shut down weak teacher educatio...      0\n",
      "1    drone places fresh kill on steps of white house      1\n",
      "2  report: majority of instances of people gettin...      1\n",
      "3  sole remaining lung filled with rich, satisfyi...      1\n",
      "4                       the gop's stockholm syndrome      0\n",
      "----------\n",
      "label\n",
      "0    11248\n",
      "1    10216\n",
      "Name: count, dtype: int64\n",
      "----------\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# loading datasets\n",
    "train_df_main = pd.read_csv('./datasets/train.csv')\n",
    "valid_df_main = pd.read_csv('./datasets/valid.csv')\n",
    "test_df_main = pd.read_csv('./datasets/test.csv')\n",
    "\n",
    "# display shapes\n",
    "print(f\"Train Shape: {train_df_main.shape}\")\n",
    "print(f\"Valid Shape: {valid_df_main.shape}\")\n",
    "print(f\"Test Shape: {test_df_main.shape}\")\n",
    "\n",
    "print(\"----------\")\n",
    "\n",
    "# preview training data\n",
    "print(train_df_main.head())\n",
    "\n",
    "print(\"----------\")\n",
    "\n",
    "# check for class balance\n",
    "print(train_df_main['label'].value_counts())\n",
    "\n",
    "print(\"----------\")\n",
    "\n",
    "# check for missing values\n",
    "print(train_df_main.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea92090",
   "metadata": {},
   "source": [
    "# Preprocessing all datasets\n",
    "\n",
    "Preprocessing includes splitting apart the sentences into tokens, lowercasing all words, and making sure there is no whitespace within the sentences themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac79f455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['states', 'slow', 'to', 'shut', 'down', 'weak', 'teacher', 'education', 'programs'], ['drone', 'places', 'fresh', 'kill', 'on', 'steps', 'of', 'white', 'house'], ['report:', 'majority', 'of', 'instances', 'of', 'people', 'getting', 'lives', 'back', 'on', 'track', 'occur', 'immediately', 'after', 'visit', 'to', 'buffalo', 'wild', 'wings'], ['sole', 'remaining', 'lung', 'filled', 'with', 'rich,', 'satisfying', 'flavor'], ['the', \"gop's\", 'stockholm', 'syndrome']]\n"
     ]
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    tokens = text.split()\n",
    "    tokens = [t for t in tokens if t]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# unprocessed text and labels\n",
    "X_train = train_df_main['text']\n",
    "X_valid = valid_df_main['text']\n",
    "X_test = test_df_main['text']\n",
    "\n",
    "y_train = train_df_main['label']\n",
    "y_valid = valid_df_main['label']\n",
    "y_test = test_df_main['label']\n",
    "\n",
    "# processed text\n",
    "X_train_processed = []\n",
    "X_valid_processed = []\n",
    "X_test_processed = []\n",
    "\n",
    "for t in X_train:\n",
    "    X_train_processed.append(preprocess(t))\n",
    "\n",
    "for t in X_valid:\n",
    "    X_valid_processed.append(preprocess(t))\n",
    "\n",
    "for t in X_test:\n",
    "    X_test_processed.append(preprocess(t))\n",
    "    \n",
    "# validating that preprocessing worked\n",
    "print(X_train_processed[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86523190",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "\n",
    "logistic regression + tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90d51a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Validation Accuracy: 0.7751\n",
      "Baseline Validation F1 Score: 0.7663\n"
     ]
    }
   ],
   "source": [
    "# baseline model\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1, 2))\n",
    "\n",
    "# the vectorizer uses the main dataframe\n",
    "X_train_baseline = vectorizer.fit_transform(X_train)\n",
    "X_valid_baseline = vectorizer.transform(X_valid)\n",
    "X_test_baseline = vectorizer.transform(X_test)\n",
    "\n",
    "baseline_model = LogisticRegression(max_iter=10000, random_state=42)\n",
    "baseline_model.fit(X_train_baseline, y_train)\n",
    "\n",
    "valid_preds = baseline_model.predict(X_valid_baseline)\n",
    "\n",
    "print(f\"Baseline Validation Accuracy: {accuracy_score(y_valid, valid_preds):.4f}\")\n",
    "print(f\"Baseline Validation F1 Score: {f1_score(y_valid, valid_preds):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98ea68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- TESTING i = 1000 -----\n",
      "Baseline Validation Accuracy: 0.7332\n",
      "Baseline Validation F1 Score: 0.7170\n",
      "----- TESTING i = 1100 -----\n",
      "Baseline Validation Accuracy: 0.7249\n",
      "Baseline Validation F1 Score: 0.7099\n",
      "----- TESTING i = 1200 -----\n",
      "Baseline Validation Accuracy: 0.7207\n",
      "Baseline Validation F1 Score: 0.7041\n",
      "----- TESTING i = 1300 -----\n",
      "Baseline Validation Accuracy: 0.7193\n",
      "Baseline Validation F1 Score: 0.7022\n",
      "----- TESTING i = 1400 -----\n",
      "Baseline Validation Accuracy: 0.7263\n",
      "Baseline Validation F1 Score: 0.7126\n",
      "----- TESTING i = 1500 -----\n",
      "Baseline Validation Accuracy: 0.7277\n",
      "Baseline Validation F1 Score: 0.7128\n",
      "----- TESTING i = 1600 -----\n",
      "Baseline Validation Accuracy: 0.7277\n",
      "Baseline Validation F1 Score: 0.7178\n",
      "----- TESTING i = 1700 -----\n",
      "Baseline Validation Accuracy: 0.7332\n",
      "Baseline Validation F1 Score: 0.7236\n",
      "----- TESTING i = 1800 -----\n",
      "Baseline Validation Accuracy: 0.7332\n",
      "Baseline Validation F1 Score: 0.7236\n",
      "----- TESTING i = 1900 -----\n",
      "Baseline Validation Accuracy: 0.7388\n",
      "Baseline Validation F1 Score: 0.7294\n",
      "----- TESTING i = 2000 -----\n",
      "Baseline Validation Accuracy: 0.7472\n",
      "Baseline Validation F1 Score: 0.7381\n",
      "----- TESTING i = 2100 -----\n",
      "Baseline Validation Accuracy: 0.7444\n",
      "Baseline Validation F1 Score: 0.7336\n",
      "----- TESTING i = 2200 -----\n",
      "Baseline Validation Accuracy: 0.7444\n",
      "Baseline Validation F1 Score: 0.7359\n",
      "----- TESTING i = 2300 -----\n",
      "Baseline Validation Accuracy: 0.7444\n",
      "Baseline Validation F1 Score: 0.7359\n",
      "----- TESTING i = 2400 -----\n",
      "Baseline Validation Accuracy: 0.7472\n",
      "Baseline Validation F1 Score: 0.7373\n",
      "----- TESTING i = 2500 -----\n",
      "Baseline Validation Accuracy: 0.7556\n",
      "Baseline Validation F1 Score: 0.7453\n",
      "----- TESTING i = 2600 -----\n",
      "Baseline Validation Accuracy: 0.7556\n",
      "Baseline Validation F1 Score: 0.7445\n",
      "----- TESTING i = 2700 -----\n",
      "Baseline Validation Accuracy: 0.7542\n",
      "Baseline Validation F1 Score: 0.7434\n",
      "----- TESTING i = 2800 -----\n",
      "Baseline Validation Accuracy: 0.7528\n",
      "Baseline Validation F1 Score: 0.7431\n",
      "----- TESTING i = 2900 -----\n",
      "Baseline Validation Accuracy: 0.7500\n",
      "Baseline Validation F1 Score: 0.7402\n",
      "----- TESTING i = 3000 -----\n",
      "Baseline Validation Accuracy: 0.7556\n",
      "Baseline Validation F1 Score: 0.7460\n",
      "----- TESTING i = 3100 -----\n",
      "Baseline Validation Accuracy: 0.7556\n",
      "Baseline Validation F1 Score: 0.7453\n",
      "----- TESTING i = 3200 -----\n",
      "Baseline Validation Accuracy: 0.7570\n",
      "Baseline Validation F1 Score: 0.7464\n",
      "----- TESTING i = 3300 -----\n",
      "Baseline Validation Accuracy: 0.7598\n",
      "Baseline Validation F1 Score: 0.7500\n",
      "----- TESTING i = 3400 -----\n",
      "Baseline Validation Accuracy: 0.7626\n",
      "Baseline Validation F1 Score: 0.7529\n",
      "----- TESTING i = 3500 -----\n",
      "Baseline Validation Accuracy: 0.7640\n",
      "Baseline Validation F1 Score: 0.7554\n",
      "----- TESTING i = 3600 -----\n",
      "Baseline Validation Accuracy: 0.7668\n",
      "Baseline Validation F1 Score: 0.7583\n",
      "----- TESTING i = 3700 -----\n",
      "Baseline Validation Accuracy: 0.7682\n",
      "Baseline Validation F1 Score: 0.7608\n",
      "----- TESTING i = 3800 -----\n",
      "Baseline Validation Accuracy: 0.7682\n",
      "Baseline Validation F1 Score: 0.7608\n",
      "----- TESTING i = 3900 -----\n",
      "Baseline Validation Accuracy: 0.7709\n",
      "Baseline Validation F1 Score: 0.7644\n",
      "----- TESTING i = 4000 -----\n",
      "Baseline Validation Accuracy: 0.7723\n",
      "Baseline Validation F1 Score: 0.7655\n",
      "----- TESTING i = 4100 -----\n",
      "Baseline Validation Accuracy: 0.7765\n",
      "Baseline Validation F1 Score: 0.7688\n",
      "----- TESTING i = 4200 -----\n",
      "Baseline Validation Accuracy: 0.7737\n",
      "Baseline Validation F1 Score: 0.7652\n",
      "----- TESTING i = 4300 -----\n",
      "Baseline Validation Accuracy: 0.7751\n",
      "Baseline Validation F1 Score: 0.7670\n",
      "----- TESTING i = 4400 -----\n",
      "Baseline Validation Accuracy: 0.7709\n",
      "Baseline Validation F1 Score: 0.7630\n",
      "----- TESTING i = 4500 -----\n",
      "Baseline Validation Accuracy: 0.7751\n",
      "Baseline Validation F1 Score: 0.7677\n",
      "----- TESTING i = 4600 -----\n",
      "Baseline Validation Accuracy: 0.7737\n",
      "Baseline Validation F1 Score: 0.7659\n",
      "----- TESTING i = 4700 -----\n",
      "Baseline Validation Accuracy: 0.7737\n",
      "Baseline Validation F1 Score: 0.7652\n",
      "----- TESTING i = 4800 -----\n",
      "Baseline Validation Accuracy: 0.7723\n",
      "Baseline Validation F1 Score: 0.7641\n",
      "----- TESTING i = 4900 -----\n",
      "Baseline Validation Accuracy: 0.7765\n",
      "Baseline Validation F1 Score: 0.7688\n",
      "----- TESTING i = 5000 -----\n",
      "Baseline Validation Accuracy: 0.7751\n",
      "Baseline Validation F1 Score: 0.7663\n",
      "----- TESTING i = 5100 -----\n",
      "Baseline Validation Accuracy: 0.7751\n",
      "Baseline Validation F1 Score: 0.7670\n",
      "----- TESTING i = 5200 -----\n",
      "Baseline Validation Accuracy: 0.7779\n",
      "Baseline Validation F1 Score: 0.7699\n",
      "----- TESTING i = 5300 -----\n",
      "Baseline Validation Accuracy: 0.7779\n",
      "Baseline Validation F1 Score: 0.7699\n",
      "----- TESTING i = 5400 -----\n",
      "Baseline Validation Accuracy: 0.7751\n",
      "Baseline Validation F1 Score: 0.7663\n",
      "----- TESTING i = 5500 -----\n",
      "Baseline Validation Accuracy: 0.7737\n",
      "Baseline Validation F1 Score: 0.7638\n",
      "----- TESTING i = 5600 -----\n",
      "Baseline Validation Accuracy: 0.7765\n",
      "Baseline Validation F1 Score: 0.7674\n",
      "----- TESTING i = 5700 -----\n",
      "Baseline Validation Accuracy: 0.7751\n",
      "Baseline Validation F1 Score: 0.7656\n",
      "----- TESTING i = 5800 -----\n",
      "Baseline Validation Accuracy: 0.7751\n",
      "Baseline Validation F1 Score: 0.7656\n",
      "----- TESTING i = 5900 -----\n",
      "Baseline Validation Accuracy: 0.7696\n",
      "Baseline Validation F1 Score: 0.7605\n",
      "----- TESTING i = 6000 -----\n",
      "Baseline Validation Accuracy: 0.7737\n",
      "Baseline Validation F1 Score: 0.7659\n",
      "----- TESTING i = 6100 -----\n",
      "Baseline Validation Accuracy: 0.7751\n",
      "Baseline Validation F1 Score: 0.7677\n",
      "----- TESTING i = 6200 -----\n",
      "Baseline Validation Accuracy: 0.7793\n",
      "Baseline Validation F1 Score: 0.7717\n",
      "----- TESTING i = 6300 -----\n",
      "Baseline Validation Accuracy: 0.7793\n",
      "Baseline Validation F1 Score: 0.7710\n",
      "----- TESTING i = 6400 -----\n",
      "Baseline Validation Accuracy: 0.7793\n",
      "Baseline Validation F1 Score: 0.7710\n",
      "----- TESTING i = 6500 -----\n",
      "Baseline Validation Accuracy: 0.7793\n",
      "Baseline Validation F1 Score: 0.7703\n",
      "----- TESTING i = 6600 -----\n",
      "Baseline Validation Accuracy: 0.7765\n",
      "Baseline Validation F1 Score: 0.7668\n",
      "----- TESTING i = 6700 -----\n",
      "Baseline Validation Accuracy: 0.7765\n",
      "Baseline Validation F1 Score: 0.7668\n",
      "----- TESTING i = 6800 -----\n",
      "Baseline Validation Accuracy: 0.7793\n",
      "Baseline Validation F1 Score: 0.7703\n",
      "----- TESTING i = 6900 -----\n",
      "Baseline Validation Accuracy: 0.7779\n",
      "Baseline Validation F1 Score: 0.7686\n",
      "----- TESTING i = 7000 -----\n",
      "Baseline Validation Accuracy: 0.7682\n",
      "Baseline Validation F1 Score: 0.7566\n",
      "----- TESTING i = 7100 -----\n",
      "Baseline Validation Accuracy: 0.7737\n",
      "Baseline Validation F1 Score: 0.7632\n",
      "----- TESTING i = 7200 -----\n",
      "Baseline Validation Accuracy: 0.7779\n",
      "Baseline Validation F1 Score: 0.7679\n",
      "----- TESTING i = 7300 -----\n",
      "Baseline Validation Accuracy: 0.7723\n",
      "Baseline Validation F1 Score: 0.7606\n",
      "----- TESTING i = 7400 -----\n",
      "Baseline Validation Accuracy: 0.7709\n",
      "Baseline Validation F1 Score: 0.7588\n",
      "----- TESTING i = 7500 -----\n",
      "Baseline Validation Accuracy: 0.7765\n",
      "Baseline Validation F1 Score: 0.7654\n",
      "----- TESTING i = 7600 -----\n",
      "Baseline Validation Accuracy: 0.7779\n",
      "Baseline Validation F1 Score: 0.7665\n",
      "----- TESTING i = 7700 -----\n",
      "Baseline Validation Accuracy: 0.7779\n",
      "Baseline Validation F1 Score: 0.7665\n",
      "----- TESTING i = 7800 -----\n",
      "Baseline Validation Accuracy: 0.7779\n",
      "Baseline Validation F1 Score: 0.7672\n",
      "----- TESTING i = 7900 -----\n",
      "Baseline Validation Accuracy: 0.7779\n",
      "Baseline Validation F1 Score: 0.7672\n",
      "----- TESTING i = 8000 -----\n",
      "Baseline Validation Accuracy: 0.7779\n",
      "Baseline Validation F1 Score: 0.7679\n",
      "----- TESTING i = 8100 -----\n",
      "Baseline Validation Accuracy: 0.7751\n",
      "Baseline Validation F1 Score: 0.7643\n",
      "----- TESTING i = 8200 -----\n",
      "Baseline Validation Accuracy: 0.7709\n",
      "Baseline Validation F1 Score: 0.7595\n",
      "----- TESTING i = 8300 -----\n",
      "Baseline Validation Accuracy: 0.7737\n",
      "Baseline Validation F1 Score: 0.7618\n",
      "----- TESTING i = 8400 -----\n",
      "Baseline Validation Accuracy: 0.7723\n",
      "Baseline Validation F1 Score: 0.7606\n",
      "----- TESTING i = 8500 -----\n",
      "Baseline Validation Accuracy: 0.7737\n",
      "Baseline Validation F1 Score: 0.7625\n",
      "----- TESTING i = 8600 -----\n",
      "Baseline Validation Accuracy: 0.7737\n",
      "Baseline Validation F1 Score: 0.7625\n",
      "----- TESTING i = 8700 -----\n",
      "Baseline Validation Accuracy: 0.7723\n",
      "Baseline Validation F1 Score: 0.7606\n",
      "----- TESTING i = 8800 -----\n",
      "Baseline Validation Accuracy: 0.7709\n",
      "Baseline Validation F1 Score: 0.7595\n",
      "----- TESTING i = 8900 -----\n",
      "Baseline Validation Accuracy: 0.7723\n",
      "Baseline Validation F1 Score: 0.7613\n",
      "----- TESTING i = 9000 -----\n",
      "Baseline Validation Accuracy: 0.7682\n",
      "Baseline Validation F1 Score: 0.7559\n",
      "----- TESTING i = 9100 -----\n",
      "Baseline Validation Accuracy: 0.7668\n",
      "Baseline Validation F1 Score: 0.7533\n",
      "----- TESTING i = 9200 -----\n",
      "Baseline Validation Accuracy: 0.7682\n",
      "Baseline Validation F1 Score: 0.7552\n",
      "----- TESTING i = 9300 -----\n",
      "Baseline Validation Accuracy: 0.7723\n",
      "Baseline Validation F1 Score: 0.7606\n",
      "----- TESTING i = 9400 -----\n",
      "Baseline Validation Accuracy: 0.7696\n",
      "Baseline Validation F1 Score: 0.7570\n",
      "----- TESTING i = 9500 -----\n",
      "Baseline Validation Accuracy: 0.7682\n",
      "Baseline Validation F1 Score: 0.7552\n",
      "----- TESTING i = 9600 -----\n",
      "Baseline Validation Accuracy: 0.7682\n",
      "Baseline Validation F1 Score: 0.7559\n",
      "----- TESTING i = 9700 -----\n",
      "Baseline Validation Accuracy: 0.7696\n",
      "Baseline Validation F1 Score: 0.7570\n",
      "----- TESTING i = 9800 -----\n",
      "Baseline Validation Accuracy: 0.7723\n",
      "Baseline Validation F1 Score: 0.7606\n",
      "----- TESTING i = 9900 -----\n",
      "Baseline Validation Accuracy: 0.7709\n",
      "Baseline Validation F1 Score: 0.7588\n"
     ]
    }
   ],
   "source": [
    "# pinpointing best feature value for vectorizer\n",
    "best_acc = 0\n",
    "best_max_features = 1000\n",
    "for i in range(1000, 10000, 100):\n",
    "    temp_vectorizer = TfidfVectorizer(stop_words='english', max_features=i, ngram_range=(1, 2))\n",
    "    \n",
    "    X_train_baseline = temp_vectorizer.fit_transform(X_train)\n",
    "    X_valid_baseline = temp_vectorizer.transform(X_valid)\n",
    "    X_test_baseline = temp_vectorizer.transform(X_test)\n",
    "\n",
    "    baseline_model = LogisticRegression(max_iter=10000, random_state=42)\n",
    "    baseline_model.fit(X_train_baseline, y_train)\n",
    "\n",
    "    valid_preds = baseline_model.predict(X_valid_baseline)\n",
    "\n",
    "    print(f\"----- TESTING i = {i} -----\")\n",
    "    print(f\"Baseline Validation Accuracy: {accuracy_score(y_valid, valid_preds):.4f}\")\n",
    "    print(f\"Baseline Validation F1 Score: {f1_score(y_valid, valid_preds):.4f}\")\n",
    "    \n",
    "    if accuracy_score(y_valid, valid_preds) > best_acc:\n",
    "        best_acc = accuracy_score(y_valid, valid_preds)\n",
    "        best_max_features = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d68b3871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7793296089385475\n",
      "6200\n"
     ]
    }
   ],
   "source": [
    "print(best_acc)\n",
    "print(best_max_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e644e2",
   "metadata": {},
   "source": [
    "# First Model\n",
    "\n",
    "SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad119ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Validation Accuracy: 0.7682\n",
      "SVM Validation F1 Score: 0.7580\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "best_vectorizer = TfidfVectorizer(stop_words='english', max_features=5200, ngram_range=(1, 2))\n",
    "\n",
    "X_train_svm = best_vectorizer.fit_transform(X_train)\n",
    "X_valid_svm = best_vectorizer.transform(X_valid)\n",
    "\n",
    "# use linearsvc since it is better than the normal svc\n",
    "# we also use td-idf with svms\n",
    "svm_model = LinearSVC(random_state=42, max_iter=10000)\n",
    "svm_model.fit(X_train_svm, y_train)\n",
    "\n",
    "valid_preds_svm = svm_model.predict(X_valid_svm)\n",
    "\n",
    "print(f\"SVM Validation Accuracy: {accuracy_score(y_valid, valid_preds_svm):.4f}\")\n",
    "print(f\"SVM Validation F1 Score: {f1_score(y_valid, valid_preds_svm):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432d2c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc_svm = 0\n",
    "best_max_features_svm = 1000\n",
    "for i in range(1000, 10000, 100):\n",
    "    temp_vectorizer = TfidfVectorizer(stop_words='english', max_features=i, ngram_range=(1, 2))\n",
    "    \n",
    "    X_train_svm = temp_vectorizer.fit_transform(X_train)\n",
    "    X_valid_svm = temp_vectorizer.transform(X_valid)\n",
    "\n",
    "    # use linearsvc since it is better than the normal svc\n",
    "    # we also use td-idf with svms\n",
    "    svm_model = LinearSVC(random_state=42, max_iter=10000)\n",
    "    svm_model.fit(X_train_svm, y_train)\n",
    "\n",
    "    valid_preds_svm = svm_model.predict(X_valid_svm)\n",
    "\n",
    "    print(f\"----- TESTING i = {i} -----\")\n",
    "    print(f\"SVM Validation Accuracy: {accuracy_score(y_valid, valid_preds_svm):.4f}\")\n",
    "    print(f\"SVM Validation F1 Score: {f1_score(y_valid, valid_preds_svm):.4f}\")\n",
    "    \n",
    "    if accuracy_score(y_valid, valid_preds_svm) > best_acc_svm:\n",
    "        best_acc_svm = accuracy_score(y_valid, valid_preds_svm)\n",
    "        best_max_features_svm = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a455541b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7821229050279329\n",
      "3500\n"
     ]
    }
   ],
   "source": [
    "print(best_acc_svm)\n",
    "print(best_max_features_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d512b1da",
   "metadata": {},
   "source": [
    "# Second Model\n",
    "\n",
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5acb8575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "336/336 [==============================] - 46s 104ms/step - loss: 0.4448 - accuracy: 0.7836 - val_loss: 0.3402 - val_accuracy: 0.8701\n",
      "Epoch 2/5\n",
      "336/336 [==============================] - 30s 91ms/step - loss: 0.2453 - accuracy: 0.9022 - val_loss: 0.3654 - val_accuracy: 0.8422\n",
      "Epoch 3/5\n",
      "336/336 [==============================] - 28s 83ms/step - loss: 0.1735 - accuracy: 0.9361 - val_loss: 0.4162 - val_accuracy: 0.8352\n",
      "Epoch 4/5\n",
      "336/336 [==============================] - 27s 81ms/step - loss: 0.1347 - accuracy: 0.9527 - val_loss: 0.4862 - val_accuracy: 0.8282\n",
      "Epoch 5/5\n",
      "336/336 [==============================] - 27s 79ms/step - loss: 0.1021 - accuracy: 0.9654 - val_loss: 0.5593 - val_accuracy: 0.8170\n",
      "23/23 [==============================] - 1s 24ms/step\n",
      "LSTM Validation Accuracy: 0.8170\n",
      "LSTM Validation F1 Score: 0.8137\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(train_df_main['text'])\n",
    "\n",
    "X_train_seq = pad_sequences(tokenizer.texts_to_sequences(train_df_main['text']), maxlen=100)\n",
    "X_valid_seq = pad_sequences(tokenizer.texts_to_sequences(valid_df_main['text']), maxlen=100)\n",
    "X_test_seq = pad_sequences(tokenizer.texts_to_sequences(test_df_main['text']), maxlen=100)\n",
    "\n",
    "# 2. Model: Define a simple LSTM network \n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=32, input_length=100),\n",
    "    LSTM(32),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 3. Training\n",
    "model.fit(X_train_seq, y_train, epochs=5, batch_size=64, validation_data=(X_valid_seq, y_valid))\n",
    "\n",
    "# 4. Evaluation\n",
    "lstm_probs = model.predict(X_valid_seq)\n",
    "lstm_preds = (lstm_probs > 0.5).astype(int)\n",
    "\n",
    "print(f\"LSTM Validation Accuracy: {accuracy_score(y_valid, lstm_preds):.4f}\")\n",
    "print(f\"LSTM Validation F1 Score: {f1_score(y_valid, lstm_preds):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28549e41",
   "metadata": {},
   "source": [
    "# Third Model\n",
    "\n",
    "BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dee1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "336/336 [==============================] - 23s 59ms/step - loss: 0.4906 - accuracy: 0.7544 - val_loss: 0.3436 - val_accuracy: 0.8589\n",
      "Epoch 2/5\n",
      "336/336 [==============================] - 22s 64ms/step - loss: 0.2620 - accuracy: 0.8989 - val_loss: 0.3528 - val_accuracy: 0.8520\n",
      "Epoch 3/5\n",
      "336/336 [==============================] - 21s 63ms/step - loss: 0.1886 - accuracy: 0.9333 - val_loss: 0.3902 - val_accuracy: 0.8478\n",
      "Epoch 4/5\n",
      "336/336 [==============================] - 23s 67ms/step - loss: 0.1452 - accuracy: 0.9491 - val_loss: 0.4610 - val_accuracy: 0.8268\n",
      "Epoch 5/5\n",
      "336/336 [==============================] - 25s 74ms/step - loss: 0.1120 - accuracy: 0.9619 - val_loss: 0.5348 - val_accuracy: 0.8282\n",
      "23/23 [==============================] - 1s 27ms/step\n",
      "Bi-LSTM Validation Accuracy: 0.8282\n",
      "Bi-LSTM Validation F1 Score: 0.8172\n"
     ]
    }
   ],
   "source": [
    "# 1. Update Sequences: Use the 'clean_text' from the previous step\n",
    "# We re-fit the tokenizer on the cleaner text\n",
    "tokenizer_clean = Tokenizer(num_words=10000)\n",
    "tokenizer_clean.fit_on_texts(train_df_main['clean_text'])\n",
    "\n",
    "X_train_seq_clean = pad_sequences(tokenizer_clean.texts_to_sequences(train_df_main['clean_text']), maxlen=100)\n",
    "X_valid_seq_clean = pad_sequences(tokenizer_clean.texts_to_sequences(valid_df_main['clean_text']), maxlen=100)\n",
    "X_test_seq_clean = pad_sequences(tokenizer_clean.texts_to_sequences(test_df_main['clean_text']), maxlen=100)\n",
    "\n",
    "# 2. Improved Model: Stacked Bi-LSTM\n",
    "# We stack two Bidirectional LSTM layers to learn more complex patterns\n",
    "bilstm_improved = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=128, input_length=100),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)), # Return sequences is required to stack another LSTM\n",
    "    Dropout(0.3),\n",
    "    Bidirectional(LSTM(32)),\n",
    "    Dropout(0.5),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "bilstm_improved.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 3. Training with Early Stopping\n",
    "# Stop training if validation loss doesn't improve for 3 epochs\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "bilstm_improved.fit(\n",
    "    X_train_seq_clean, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_valid_seq_clean, y_valid),\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# 4. Evaluation\n",
    "probs_bilstm_improved = bilstm_improved.predict(X_valid_seq_clean)\n",
    "preds_bilstm_improved = (probs_bilstm_improved > 0.5).astype(int)\n",
    "\n",
    "print(f\"Improved Bi-LSTM Accuracy: {accuracy_score(y_valid, preds_bilstm_improved):.4f}\")\n",
    "print(f\"Improved Bi-LSTM F1 Score: {f1_score(y_valid, preds_bilstm_improved):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b790d0e6",
   "metadata": {},
   "source": [
    "# Fourth Model\n",
    "\n",
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3c6ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Model: 1D Convolutional Neural Network\n",
    "# - Conv1D with kernel_size=5 looks at 5-word windows to find sarcastic phrases\n",
    "# - GlobalMaxPooling1D keeps only the strongest signal found in the text\n",
    "cnn_model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=128, input_length=100),\n",
    "    Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 2. Training\n",
    "# We use the same 'clean' sequences and early stopping as before\n",
    "cnn_model.fit(\n",
    "    X_train_seq_clean, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_valid_seq_clean, y_valid),\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# 3. Evaluation\n",
    "probs_cnn = cnn_model.predict(X_valid_seq_clean)\n",
    "preds_cnn = (probs_cnn > 0.5).astype(int)\n",
    "\n",
    "print(f\"CNN Validation Accuracy: {accuracy_score(y_valid, preds_cnn):.4f}\")\n",
    "print(f\"CNN Validation F1 Score: {f1_score(y_valid, preds_cnn):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094ae452",
   "metadata": {},
   "source": [
    "# Ensemble Model\n",
    "\n",
    "All of the models join together and create a beautiful new model to average out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27972ea8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 5000 features, but LinearSVC is expecting 9900 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m X_test_ensemble \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 1. Get predictions for the Test Set from all 3 models\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# SVM (uses TF-IDF features)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m pred_test_svm \u001b[38;5;241m=\u001b[39m \u001b[43msvm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_ensemble\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# LSTM (uses Sequence features)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m pred_test_lstm \u001b[38;5;241m=\u001b[39m (model\u001b[38;5;241m.\u001b[39mpredict(X_test_seq) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[0;32m~/miniconda3/envs/math/lib/python3.10/site-packages/sklearn/linear_model/_base.py:451\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 451\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    453\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/math/lib/python3.10/site-packages/sklearn/linear_model/_base.py:432\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    429\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/miniconda3/envs/math/lib/python3.10/site-packages/sklearn/base.py:626\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/math/lib/python3.10/site-packages/sklearn/base.py:415\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 5000 features, but LinearSVC is expecting 9900 features as input."
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1, 2))\n",
    "\n",
    "# the vectorizer uses the main dataframe\n",
    "X_train_ensemble = vectorizer.fit_transform(X_train)\n",
    "X_valid_ensemble = vectorizer.transform(X_valid)\n",
    "X_test_ensemble = vectorizer.transform(X_test)\n",
    "\n",
    "# 1. Get predictions for the Test Set from all 3 models\n",
    "# SVM (uses TF-IDF features)\n",
    "pred_test_svm = svm_model.predict(X_test_ensemble)\n",
    "\n",
    "# LSTM (uses Sequence features)\n",
    "pred_test_lstm = (model.predict(X_test_seq) > 0.5).astype(int).flatten()\n",
    "\n",
    "# Bi-LSTM (uses Sequence features)\n",
    "pred_test_bilstm = (bilstm_improved.predict(X_test_seq) > 0.5).astype(int).flatten()\n",
    "\n",
    "# CNN\n",
    "pred_test_cnn = (cnn_model.predict(X_test_seq) > 0.5).astype(int).flatten()\n",
    "\n",
    "# 2. Ensemble Voting (Majority Vote)\n",
    "# Sum the predictions (0 or 1). If sum is 2 or 3, majority is 1.\n",
    "test_votes = pred_test_svm + pred_test_lstm + pred_test_bilstm + pred_test_cnn\n",
    "pred_test_ensemble = (test_votes >= 2).astype(int)\n",
    "\n",
    "# 3. Report detailed metrics\n",
    "print(\"Final Evaluation on Test Set:\")\n",
    "print(classification_report(test_df_main['label'], pred_test_ensemble, digits=4))\n",
    "\n",
    "# 4. Confusion Matrix (Row: True, Col: Predicted)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(test_df_main['label'], pred_test_ensemble))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
