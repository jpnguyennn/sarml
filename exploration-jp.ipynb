{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c07ba54c",
   "metadata": {},
   "source": [
    "# Import all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b7432b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# baseline model libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# first model\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd8b19b",
   "metadata": {},
   "source": [
    "# Exploring the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e77d1111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (21464, 2)\n",
      "Valid Shape: (716, 2)\n",
      "Test Shape: (966, 2)\n",
      "----------\n",
      "                                                text  label\n",
      "0  states slow to shut down weak teacher educatio...      0\n",
      "1    drone places fresh kill on steps of white house      1\n",
      "2  report: majority of instances of people gettin...      1\n",
      "3  sole remaining lung filled with rich, satisfyi...      1\n",
      "4                       the gop's stockholm syndrome      0\n",
      "----------\n",
      "label\n",
      "0    11248\n",
      "1    10216\n",
      "Name: count, dtype: int64\n",
      "----------\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# loading datasets\n",
    "train_df_main = pd.read_csv('./datasets/train.csv')\n",
    "valid_df_main = pd.read_csv('./datasets/valid.csv')\n",
    "test_df_main = pd.read_csv('./datasets/test.csv')\n",
    "\n",
    "# display shapes\n",
    "print(f\"Train Shape: {train_df_main.shape}\")\n",
    "print(f\"Valid Shape: {valid_df_main.shape}\")\n",
    "print(f\"Test Shape: {test_df_main.shape}\")\n",
    "\n",
    "print(\"----------\")\n",
    "\n",
    "# preview training data\n",
    "print(train_df_main.head())\n",
    "\n",
    "print(\"----------\")\n",
    "\n",
    "# check for class balance\n",
    "print(train_df_main['label'].value_counts())\n",
    "\n",
    "print(\"----------\")\n",
    "\n",
    "# check for missing values\n",
    "print(train_df_main.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea92090",
   "metadata": {},
   "source": [
    "# Preprocessing all datasets\n",
    "\n",
    "Preprocessing includes splitting apart the sentences into tokens, lowercasing all words, and making sure there is no whitespace within the sentences themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac79f455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['states', 'slow', 'to', 'shut', 'down', 'weak', 'teacher', 'education', 'programs'], ['drone', 'places', 'fresh', 'kill', 'on', 'steps', 'of', 'white', 'house'], ['report:', 'majority', 'of', 'instances', 'of', 'people', 'getting', 'lives', 'back', 'on', 'track', 'occur', 'immediately', 'after', 'visit', 'to', 'buffalo', 'wild', 'wings'], ['sole', 'remaining', 'lung', 'filled', 'with', 'rich,', 'satisfying', 'flavor'], ['the', \"gop's\", 'stockholm', 'syndrome']]\n"
     ]
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    tokens = text.split()\n",
    "    tokens = [t for t in tokens if t]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# unprocessed text and labels\n",
    "X_train = train_df_main['text']\n",
    "X_valid = valid_df_main['text']\n",
    "X_test = test_df_main['text']\n",
    "\n",
    "y_train = train_df_main['label']\n",
    "y_valid = valid_df_main['label']\n",
    "y_test = test_df_main['label']\n",
    "\n",
    "# processed text\n",
    "X_train_processed = []\n",
    "X_valid_processed = []\n",
    "X_test_processed = []\n",
    "\n",
    "for t in X_train:\n",
    "    X_train_processed.append(preprocess(t))\n",
    "\n",
    "for t in X_valid:\n",
    "    X_valid_processed.append(preprocess(t))\n",
    "\n",
    "for t in X_test:\n",
    "    X_test_processed.append(preprocess(t))\n",
    "    \n",
    "# validating that preprocessing worked\n",
    "print(X_train_processed[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86523190",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "\n",
    "logistic regression + tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90d51a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Validation Accuracy: 0.7751\n",
      "Baseline Validation F1 Score: 0.7663\n"
     ]
    }
   ],
   "source": [
    "# baseline model\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1, 2))\n",
    "\n",
    "# the vectorizer uses the main dataframe\n",
    "X_train_baseline = vectorizer.fit_transform(X_train)\n",
    "X_valid_baseline = vectorizer.transform(X_valid)\n",
    "X_test_baseline = vectorizer.transform(X_test)\n",
    "\n",
    "baseline_model = LogisticRegression(max_iter=10000, random_state=42)\n",
    "baseline_model.fit(X_train_baseline, y_train)\n",
    "\n",
    "valid_preds = baseline_model.predict(X_valid_baseline)\n",
    "\n",
    "print(f\"Baseline Validation Accuracy: {accuracy_score(y_valid, valid_preds):.4f}\")\n",
    "print(f\"Baseline Validation F1 Score: {f1_score(y_valid, valid_preds):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e98ea68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- TESTING i = 1000 -----\n",
      "Baseline Validation Accuracy: 0.7332\n",
      "Baseline Validation F1 Score: 0.7170\n",
      "----- TESTING i = 1100 -----\n",
      "Baseline Validation Accuracy: 0.7249\n",
      "Baseline Validation F1 Score: 0.7099\n",
      "----- TESTING i = 1200 -----\n",
      "Baseline Validation Accuracy: 0.7207\n",
      "Baseline Validation F1 Score: 0.7041\n",
      "----- TESTING i = 1300 -----\n",
      "Baseline Validation Accuracy: 0.7193\n",
      "Baseline Validation F1 Score: 0.7022\n",
      "----- TESTING i = 1400 -----\n",
      "Baseline Validation Accuracy: 0.7263\n",
      "Baseline Validation F1 Score: 0.7126\n",
      "----- TESTING i = 1500 -----\n",
      "Baseline Validation Accuracy: 0.7277\n",
      "Baseline Validation F1 Score: 0.7128\n",
      "----- TESTING i = 1600 -----\n",
      "Baseline Validation Accuracy: 0.7277\n",
      "Baseline Validation F1 Score: 0.7178\n",
      "----- TESTING i = 1700 -----\n",
      "Baseline Validation Accuracy: 0.7332\n",
      "Baseline Validation F1 Score: 0.7236\n",
      "----- TESTING i = 1800 -----\n",
      "Baseline Validation Accuracy: 0.7332\n",
      "Baseline Validation F1 Score: 0.7236\n",
      "----- TESTING i = 1900 -----\n",
      "Baseline Validation Accuracy: 0.7388\n",
      "Baseline Validation F1 Score: 0.7294\n",
      "----- TESTING i = 2000 -----\n",
      "Baseline Validation Accuracy: 0.7472\n",
      "Baseline Validation F1 Score: 0.7381\n",
      "----- TESTING i = 2100 -----\n",
      "Baseline Validation Accuracy: 0.7444\n",
      "Baseline Validation F1 Score: 0.7336\n",
      "----- TESTING i = 2200 -----\n",
      "Baseline Validation Accuracy: 0.7444\n",
      "Baseline Validation F1 Score: 0.7359\n",
      "----- TESTING i = 2300 -----\n",
      "Baseline Validation Accuracy: 0.7444\n",
      "Baseline Validation F1 Score: 0.7359\n",
      "----- TESTING i = 2400 -----\n",
      "Baseline Validation Accuracy: 0.7472\n",
      "Baseline Validation F1 Score: 0.7373\n",
      "----- TESTING i = 2500 -----\n",
      "Baseline Validation Accuracy: 0.7556\n",
      "Baseline Validation F1 Score: 0.7453\n",
      "----- TESTING i = 2600 -----\n",
      "Baseline Validation Accuracy: 0.7556\n",
      "Baseline Validation F1 Score: 0.7445\n",
      "----- TESTING i = 2700 -----\n",
      "Baseline Validation Accuracy: 0.7542\n",
      "Baseline Validation F1 Score: 0.7434\n",
      "----- TESTING i = 2800 -----\n",
      "Baseline Validation Accuracy: 0.7528\n",
      "Baseline Validation F1 Score: 0.7431\n",
      "----- TESTING i = 2900 -----\n",
      "Baseline Validation Accuracy: 0.7500\n",
      "Baseline Validation F1 Score: 0.7402\n",
      "----- TESTING i = 3000 -----\n",
      "Baseline Validation Accuracy: 0.7556\n",
      "Baseline Validation F1 Score: 0.7460\n",
      "----- TESTING i = 3100 -----\n",
      "Baseline Validation Accuracy: 0.7556\n",
      "Baseline Validation F1 Score: 0.7453\n",
      "----- TESTING i = 3200 -----\n",
      "Baseline Validation Accuracy: 0.7570\n",
      "Baseline Validation F1 Score: 0.7464\n",
      "----- TESTING i = 3300 -----\n",
      "Baseline Validation Accuracy: 0.7598\n",
      "Baseline Validation F1 Score: 0.7500\n",
      "----- TESTING i = 3400 -----\n",
      "Baseline Validation Accuracy: 0.7626\n",
      "Baseline Validation F1 Score: 0.7529\n",
      "----- TESTING i = 3500 -----\n",
      "Baseline Validation Accuracy: 0.7640\n",
      "Baseline Validation F1 Score: 0.7554\n",
      "----- TESTING i = 3600 -----\n",
      "Baseline Validation Accuracy: 0.7668\n",
      "Baseline Validation F1 Score: 0.7583\n",
      "----- TESTING i = 3700 -----\n",
      "Baseline Validation Accuracy: 0.7682\n",
      "Baseline Validation F1 Score: 0.7608\n",
      "----- TESTING i = 3800 -----\n",
      "Baseline Validation Accuracy: 0.7682\n",
      "Baseline Validation F1 Score: 0.7608\n",
      "----- TESTING i = 3900 -----\n",
      "Baseline Validation Accuracy: 0.7709\n",
      "Baseline Validation F1 Score: 0.7644\n",
      "----- TESTING i = 4000 -----\n",
      "Baseline Validation Accuracy: 0.7723\n",
      "Baseline Validation F1 Score: 0.7655\n",
      "----- TESTING i = 4100 -----\n",
      "Baseline Validation Accuracy: 0.7765\n",
      "Baseline Validation F1 Score: 0.7688\n",
      "----- TESTING i = 4200 -----\n",
      "Baseline Validation Accuracy: 0.7737\n",
      "Baseline Validation F1 Score: 0.7652\n",
      "----- TESTING i = 4300 -----\n",
      "Baseline Validation Accuracy: 0.7751\n",
      "Baseline Validation F1 Score: 0.7670\n",
      "----- TESTING i = 4400 -----\n",
      "Baseline Validation Accuracy: 0.7709\n",
      "Baseline Validation F1 Score: 0.7630\n",
      "----- TESTING i = 4500 -----\n",
      "Baseline Validation Accuracy: 0.7751\n",
      "Baseline Validation F1 Score: 0.7677\n",
      "----- TESTING i = 4600 -----\n",
      "Baseline Validation Accuracy: 0.7737\n",
      "Baseline Validation F1 Score: 0.7659\n",
      "----- TESTING i = 4700 -----\n",
      "Baseline Validation Accuracy: 0.7737\n",
      "Baseline Validation F1 Score: 0.7652\n",
      "----- TESTING i = 4800 -----\n",
      "Baseline Validation Accuracy: 0.7723\n",
      "Baseline Validation F1 Score: 0.7641\n",
      "----- TESTING i = 4900 -----\n",
      "Baseline Validation Accuracy: 0.7765\n",
      "Baseline Validation F1 Score: 0.7688\n",
      "----- TESTING i = 5000 -----\n",
      "Baseline Validation Accuracy: 0.7751\n",
      "Baseline Validation F1 Score: 0.7663\n",
      "----- TESTING i = 5100 -----\n",
      "Baseline Validation Accuracy: 0.7751\n",
      "Baseline Validation F1 Score: 0.7670\n",
      "----- TESTING i = 5200 -----\n",
      "Baseline Validation Accuracy: 0.7779\n",
      "Baseline Validation F1 Score: 0.7699\n",
      "----- TESTING i = 5300 -----\n",
      "Baseline Validation Accuracy: 0.7779\n",
      "Baseline Validation F1 Score: 0.7699\n",
      "----- TESTING i = 5400 -----\n",
      "Baseline Validation Accuracy: 0.7751\n",
      "Baseline Validation F1 Score: 0.7663\n",
      "----- TESTING i = 5500 -----\n",
      "Baseline Validation Accuracy: 0.7737\n",
      "Baseline Validation F1 Score: 0.7638\n",
      "----- TESTING i = 5600 -----\n",
      "Baseline Validation Accuracy: 0.7765\n",
      "Baseline Validation F1 Score: 0.7674\n",
      "----- TESTING i = 5700 -----\n",
      "Baseline Validation Accuracy: 0.7751\n",
      "Baseline Validation F1 Score: 0.7656\n",
      "----- TESTING i = 5800 -----\n",
      "Baseline Validation Accuracy: 0.7751\n",
      "Baseline Validation F1 Score: 0.7656\n",
      "----- TESTING i = 5900 -----\n",
      "Baseline Validation Accuracy: 0.7696\n",
      "Baseline Validation F1 Score: 0.7605\n",
      "----- TESTING i = 6000 -----\n",
      "Baseline Validation Accuracy: 0.7737\n",
      "Baseline Validation F1 Score: 0.7659\n",
      "----- TESTING i = 6100 -----\n",
      "Baseline Validation Accuracy: 0.7751\n",
      "Baseline Validation F1 Score: 0.7677\n",
      "----- TESTING i = 6200 -----\n",
      "Baseline Validation Accuracy: 0.7793\n",
      "Baseline Validation F1 Score: 0.7717\n",
      "----- TESTING i = 6300 -----\n",
      "Baseline Validation Accuracy: 0.7793\n",
      "Baseline Validation F1 Score: 0.7710\n",
      "----- TESTING i = 6400 -----\n",
      "Baseline Validation Accuracy: 0.7793\n",
      "Baseline Validation F1 Score: 0.7710\n",
      "----- TESTING i = 6500 -----\n",
      "Baseline Validation Accuracy: 0.7793\n",
      "Baseline Validation F1 Score: 0.7703\n",
      "----- TESTING i = 6600 -----\n",
      "Baseline Validation Accuracy: 0.7765\n",
      "Baseline Validation F1 Score: 0.7668\n",
      "----- TESTING i = 6700 -----\n",
      "Baseline Validation Accuracy: 0.7765\n",
      "Baseline Validation F1 Score: 0.7668\n",
      "----- TESTING i = 6800 -----\n",
      "Baseline Validation Accuracy: 0.7793\n",
      "Baseline Validation F1 Score: 0.7703\n",
      "----- TESTING i = 6900 -----\n",
      "Baseline Validation Accuracy: 0.7779\n",
      "Baseline Validation F1 Score: 0.7686\n",
      "----- TESTING i = 7000 -----\n",
      "Baseline Validation Accuracy: 0.7682\n",
      "Baseline Validation F1 Score: 0.7566\n",
      "----- TESTING i = 7100 -----\n",
      "Baseline Validation Accuracy: 0.7737\n",
      "Baseline Validation F1 Score: 0.7632\n",
      "----- TESTING i = 7200 -----\n",
      "Baseline Validation Accuracy: 0.7779\n",
      "Baseline Validation F1 Score: 0.7679\n",
      "----- TESTING i = 7300 -----\n",
      "Baseline Validation Accuracy: 0.7723\n",
      "Baseline Validation F1 Score: 0.7606\n",
      "----- TESTING i = 7400 -----\n",
      "Baseline Validation Accuracy: 0.7709\n",
      "Baseline Validation F1 Score: 0.7588\n",
      "----- TESTING i = 7500 -----\n",
      "Baseline Validation Accuracy: 0.7765\n",
      "Baseline Validation F1 Score: 0.7654\n",
      "----- TESTING i = 7600 -----\n",
      "Baseline Validation Accuracy: 0.7779\n",
      "Baseline Validation F1 Score: 0.7665\n",
      "----- TESTING i = 7700 -----\n",
      "Baseline Validation Accuracy: 0.7779\n",
      "Baseline Validation F1 Score: 0.7665\n",
      "----- TESTING i = 7800 -----\n",
      "Baseline Validation Accuracy: 0.7779\n",
      "Baseline Validation F1 Score: 0.7672\n",
      "----- TESTING i = 7900 -----\n",
      "Baseline Validation Accuracy: 0.7779\n",
      "Baseline Validation F1 Score: 0.7672\n",
      "----- TESTING i = 8000 -----\n",
      "Baseline Validation Accuracy: 0.7779\n",
      "Baseline Validation F1 Score: 0.7679\n",
      "----- TESTING i = 8100 -----\n",
      "Baseline Validation Accuracy: 0.7751\n",
      "Baseline Validation F1 Score: 0.7643\n",
      "----- TESTING i = 8200 -----\n",
      "Baseline Validation Accuracy: 0.7709\n",
      "Baseline Validation F1 Score: 0.7595\n",
      "----- TESTING i = 8300 -----\n",
      "Baseline Validation Accuracy: 0.7737\n",
      "Baseline Validation F1 Score: 0.7618\n",
      "----- TESTING i = 8400 -----\n",
      "Baseline Validation Accuracy: 0.7723\n",
      "Baseline Validation F1 Score: 0.7606\n",
      "----- TESTING i = 8500 -----\n",
      "Baseline Validation Accuracy: 0.7737\n",
      "Baseline Validation F1 Score: 0.7625\n",
      "----- TESTING i = 8600 -----\n",
      "Baseline Validation Accuracy: 0.7737\n",
      "Baseline Validation F1 Score: 0.7625\n",
      "----- TESTING i = 8700 -----\n",
      "Baseline Validation Accuracy: 0.7723\n",
      "Baseline Validation F1 Score: 0.7606\n",
      "----- TESTING i = 8800 -----\n",
      "Baseline Validation Accuracy: 0.7709\n",
      "Baseline Validation F1 Score: 0.7595\n",
      "----- TESTING i = 8900 -----\n",
      "Baseline Validation Accuracy: 0.7723\n",
      "Baseline Validation F1 Score: 0.7613\n",
      "----- TESTING i = 9000 -----\n",
      "Baseline Validation Accuracy: 0.7682\n",
      "Baseline Validation F1 Score: 0.7559\n",
      "----- TESTING i = 9100 -----\n",
      "Baseline Validation Accuracy: 0.7668\n",
      "Baseline Validation F1 Score: 0.7533\n",
      "----- TESTING i = 9200 -----\n",
      "Baseline Validation Accuracy: 0.7682\n",
      "Baseline Validation F1 Score: 0.7552\n",
      "----- TESTING i = 9300 -----\n",
      "Baseline Validation Accuracy: 0.7723\n",
      "Baseline Validation F1 Score: 0.7606\n",
      "----- TESTING i = 9400 -----\n",
      "Baseline Validation Accuracy: 0.7696\n",
      "Baseline Validation F1 Score: 0.7570\n",
      "----- TESTING i = 9500 -----\n",
      "Baseline Validation Accuracy: 0.7682\n",
      "Baseline Validation F1 Score: 0.7552\n",
      "----- TESTING i = 9600 -----\n",
      "Baseline Validation Accuracy: 0.7682\n",
      "Baseline Validation F1 Score: 0.7559\n",
      "----- TESTING i = 9700 -----\n",
      "Baseline Validation Accuracy: 0.7696\n",
      "Baseline Validation F1 Score: 0.7570\n",
      "----- TESTING i = 9800 -----\n",
      "Baseline Validation Accuracy: 0.7723\n",
      "Baseline Validation F1 Score: 0.7606\n",
      "----- TESTING i = 9900 -----\n",
      "Baseline Validation Accuracy: 0.7709\n",
      "Baseline Validation F1 Score: 0.7588\n"
     ]
    }
   ],
   "source": [
    "# pinpointing best feature value for vectorizer\n",
    "best_acc = 0\n",
    "best_max_features = 4000\n",
    "for i in range(1000, 10000, 100):\n",
    "    temp_vectorizer = TfidfVectorizer(stop_words='english', max_features=i, ngram_range=(1, 2))\n",
    "    \n",
    "    X_train_baseline = temp_vectorizer.fit_transform(X_train)\n",
    "    X_valid_baseline = temp_vectorizer.transform(X_valid)\n",
    "    X_test_baseline = temp_vectorizer.transform(X_test)\n",
    "\n",
    "    baseline_model = LogisticRegression(max_iter=10000, random_state=42)\n",
    "    baseline_model.fit(X_train_baseline, y_train)\n",
    "\n",
    "    valid_preds = baseline_model.predict(X_valid_baseline)\n",
    "\n",
    "    print(f\"----- TESTING i = {i} -----\")\n",
    "    print(f\"Baseline Validation Accuracy: {accuracy_score(y_valid, valid_preds):.4f}\")\n",
    "    print(f\"Baseline Validation F1 Score: {f1_score(y_valid, valid_preds):.4f}\")\n",
    "    \n",
    "    if accuracy_score(y_valid, valid_preds) > best_acc:\n",
    "        best_acc = accuracy_score(y_valid, valid_preds)\n",
    "        best_max_features = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d68b3871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7793296089385475\n",
      "6200\n"
     ]
    }
   ],
   "source": [
    "print(best_acc)\n",
    "print(best_max_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3898e7e0",
   "metadata": {},
   "source": [
    "# Possible Model\n",
    "\n",
    "Random Forests w/ Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae69908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done!\n",
      "\n",
      "Validation Set Results:\n",
      "Accuracy: 0.7765\n",
      "F1-Score: 0.7753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "def sentence_to_vec(texts, model):\n",
    "    vectors = []\n",
    "    \n",
    "    for text in texts:\n",
    "        temp_vectors = []\n",
    "        tokens = wv_preprocess(text)\n",
    "        \n",
    "        for token in tokens:\n",
    "            if token in model:\n",
    "                temp_vectors.append(model[token])\n",
    "        \n",
    "        if len(temp_vectors) == 0:\n",
    "            vectors.append(np.zeros(model.vector_size))\n",
    "        else:\n",
    "            vectors.append(np.max(temp_vectors, axis=0))\n",
    "    \n",
    "    return np.array(vectors)\n",
    "\n",
    "X_train = train_df['text']\n",
    "X_valid = valid_df['text']\n",
    "y_train = train_df['label']\n",
    "y_valid = valid_df['label']\n",
    "model = api.load('glove-wiki-gigaword-100')\n",
    "\n",
    "X_train_rf = sentence_to_vec(X_train, model)\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,      # Number of trees\n",
    "    max_depth=20,          # Limit depth to prevent overfitting\n",
    "    min_samples_split=5,   # Need at least 5 samples to split\n",
    "    random_state=42,\n",
    "    n_jobs=-1,             # Use all CPU cores\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train_rf, y_train)\n",
    "print('Training done!')\n",
    "\n",
    "X_valid_rf = sentence_to_vec(X_valid, model)\n",
    "y_val_pred = rf_model.predict(X_valid_rf)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_valid, y_val_pred)\n",
    "f1 = f1_score(y_valid, y_val_pred)\n",
    "\n",
    "print(\"\\nValidation Set Results:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e644e2",
   "metadata": {},
   "source": [
    "# First Model\n",
    "\n",
    "SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad119ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Validation Accuracy: 0.7682\n",
      "SVM Validation F1 Score: 0.7580\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "best_vectorizer = TfidfVectorizer(stop_words='english', max_features=5200, ngram_range=(1, 2))\n",
    "\n",
    "X_train_svm = best_vectorizer.fit_transform(X_train)\n",
    "X_valid_svm = best_vectorizer.transform(X_valid)\n",
    "\n",
    "# use linearsvc since it is better than the normal svc\n",
    "# we also use td-idf with svms\n",
    "svm_model = LinearSVC(random_state=42, max_iter=10000)\n",
    "svm_model.fit(X_train_svm, y_train)\n",
    "\n",
    "valid_preds_svm = svm_model.predict(X_valid_svm)\n",
    "\n",
    "print(f\"SVM Validation Accuracy: {accuracy_score(y_valid, valid_preds_svm):.4f}\")\n",
    "print(f\"SVM Validation F1 Score: {f1_score(y_valid, valid_preds_svm):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432d2c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
